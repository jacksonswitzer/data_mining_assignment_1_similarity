{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30a67f30-0009-4f07-8bf2-f7eaf6c03fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3c624ff-e9b1-4531-983f-aaaf50dd2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a9506825-26e0-4846-bd9e-eda6aa13fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = pd.read_csv('data/tokens.txt', header=None, delimiter=' ', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "569f933d-f31d-42dc-a3f7-bac1dc82d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.to_pickle('data/tokens.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e38a70-658d-42e0-9542-b9068d66e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = pd.read_pickle('data/tokens.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f077833-2dda-4f1e-9084-be6bc12440b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0         1         2\n",
      "0    the  0.306717 -0.320530\n",
      "1      ,  0.022532  0.320788\n",
      "2      . -0.075626  0.369955\n",
      "3     of  0.487177 -0.193218\n",
      "4     to  0.173940 -0.104660\n",
      "5    and  0.222883 -0.001161\n",
      "6     in  0.712315  0.451855\n",
      "7      a  0.048874  0.379618\n",
      "8      \"  0.019833  0.136752\n",
      "9      - -0.308798 -0.711716\n",
      "10    's  0.777245 -0.275744\n",
      "11   for  0.312680  0.062339\n",
      "12  that  0.465040 -0.383865\n",
      "13    on  0.285893 -0.133414\n",
      "14   was  0.444401  0.233967\n",
      "15    is  0.826911 -0.049384\n",
      "16  said -0.434792  0.498616\n",
      "17  with  0.213500  0.433140\n",
      "18    he  0.753313  0.336813\n",
      "19    as  0.414907 -0.157948\n"
     ]
    }
   ],
   "source": [
    "#used to test after reading tokens.txt to see if I had done it right\n",
    "#then used to see what the first ten words were\n",
    "print(d.iloc[:20, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c56b5103-2cdf-4f45-b50f-fef8da6e3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ten_words = d.iloc[[0,3,4,5,6,7,11,12,13,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "73f54333-153d-4a4f-9ef4-793a83bd695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.145 0.199 0.205 0.153 0.18  0.182 0.138 0.155 0.202]\n",
      " [0.145 0.    0.271 0.191 0.173 0.209 0.187 0.217 0.231 0.288]\n",
      " [0.199 0.271 0.    0.194 0.218 0.25  0.163 0.164 0.183 0.322]\n",
      " [0.205 0.191 0.194 0.    0.172 0.262 0.144 0.172 0.176 0.273]\n",
      " [0.153 0.173 0.218 0.172 0.    0.189 0.179 0.203 0.17  0.2  ]\n",
      " [0.18  0.209 0.25  0.262 0.189 0.    0.17  0.189 0.21  0.216]\n",
      " [0.182 0.187 0.163 0.144 0.179 0.17  0.    0.164 0.138 0.246]\n",
      " [0.138 0.217 0.164 0.172 0.203 0.189 0.164 0.    0.189 0.235]\n",
      " [0.155 0.231 0.183 0.176 0.17  0.21  0.138 0.189 0.    0.236]\n",
      " [0.202 0.288 0.322 0.273 0.2   0.216 0.246 0.235 0.236 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "#cosine similarity = v1 dot v2 / (norm(v1) * norm(v2))\n",
    "#cosine distance = 1 - cosine similarity\n",
    "\n",
    "cos_similarities = np.empty((10,10))\n",
    "for i in range(10):\n",
    "    for j in range (10):\n",
    "        cos_similarities[i, j] = np.dot(first_ten_words.iloc[i, 1:], first_ten_words.iloc[j, 1:]) / (np.linalg.norm(first_ten_words.iloc[i, 1:]) * np.linalg.norm(first_ten_words.iloc[j, 1:]))\n",
    "cos_similarities = np.clip(cos_similarities, -1, 1) #clipped to fix a rounding error\n",
    "cos_distances = 1 - cos_similarities\n",
    "\n",
    "print(np.round(cos_distances, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e55a6423-0fe2-4ded-a648-0f3d96841e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.545 0.642 0.652 0.56  0.61  0.613 0.532 0.564 0.647]\n",
      " [0.545 0.    0.753 0.628 0.598 0.658 0.622 0.671 0.693 0.779]\n",
      " [0.642 0.753 0.    0.633 0.673 0.723 0.579 0.581 0.614 0.826]\n",
      " [0.652 0.628 0.633 0.    0.595 0.741 0.544 0.596 0.602 0.757]\n",
      " [0.56  0.598 0.673 0.595 0.    0.626 0.607 0.649 0.592 0.644]\n",
      " [0.61  0.658 0.723 0.741 0.626 0.    0.591 0.625 0.661 0.669]\n",
      " [0.613 0.622 0.579 0.544 0.607 0.591 0.    0.581 0.531 0.717]\n",
      " [0.532 0.671 0.581 0.596 0.649 0.625 0.581 0.    0.624 0.7  ]\n",
      " [0.564 0.693 0.614 0.602 0.592 0.661 0.531 0.624 0.    0.701]\n",
      " [0.647 0.779 0.826 0.757 0.644 0.669 0.717 0.7   0.701 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "#angular distance = arccos(v1 dot v2 / (norm(v1) * norm(v2)))\n",
    "\n",
    "angular_distances = np.arccos(cos_similarities)\n",
    "\n",
    "print(np.round(angular_distances, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "707e3a6b-0649-4e2c-8658-6d1467e1609f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word1 word2  angular distance\n",
      "34    on   for            0.5311\n",
      "21  that   the            0.5319\n",
      "18   for   and            0.5438\n",
      "0     of   the            0.5455\n",
      "6     in   the            0.5601\n",
      "28    on   the            0.5639\n",
      "17   for    to            0.5790\n",
      "27  that   for            0.5813\n",
      "23  that    to            0.5814\n",
      "20   for     a            0.5908\n",
      "32    on    in            0.5924\n",
      "9     in   and            0.5945\n",
      "24  that   and            0.5961\n",
      "7     in    of            0.5979\n",
      "31    on   and            0.6021\n",
      "19   for    in            0.6070\n",
      "10     a   the            0.6097\n",
      "15   for   the            0.6126\n",
      "30    on    to            0.6145\n",
      "16   for    of            0.6223\n",
      "35    on  that            0.6245\n",
      "26  that     a            0.6250\n",
      "14     a    in            0.6257\n",
      "4    and    of            0.6276\n",
      "5    and    to            0.6329\n",
      "1     to   the            0.6416\n",
      "40   was    in            0.6437\n",
      "36   was   the            0.6470\n",
      "25  that    in            0.6493\n",
      "3    and   the            0.6518\n",
      "11     a    of            0.6582\n",
      "33    on     a            0.6607\n",
      "41   was     a            0.6690\n",
      "22  that    of            0.6709\n",
      "8     in    to            0.6727\n",
      "29    on    of            0.6930\n",
      "43   was  that            0.7000\n",
      "44   was    on            0.7006\n",
      "42   was   for            0.7165\n",
      "12     a    to            0.7225\n",
      "13     a   and            0.7407\n",
      "2     to    of            0.7534\n",
      "39   was   and            0.7571\n",
      "37   was    of            0.7790\n",
      "38   was    to            0.8256\n"
     ]
    }
   ],
   "source": [
    "ang_dis_arr_rounded_no_repeats = np.tril(np.round(angular_distances, decimals=4))\n",
    "ang_dis_df = pd.DataFrame(columns=['word1', 'word2', 'angular distance'])\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if ang_dis_arr_rounded_no_repeats[i,j] != 0:\n",
    "            ang_dis_df.loc[len(ang_dis_df)] = {'word1': first_ten_words.iloc[i,0], 'word2': first_ten_words.iloc[j,0], 'angular distance': ang_dis_arr_rounded_no_repeats[i,j]}\n",
    "\n",
    "ang_dis_dif = ang_dis_df.sort_values('angular distance')\n",
    "print(ang_dis_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722227e5-d512-4723-af17-5208e1306980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for comparison (make sure the list is the same with both distances measures)\n",
    "\n",
    "cos_dis_arr_rounded_no_repeats = np.tril(np.round(cos_distances, decimals=4))\n",
    "cos_dis_df = pd.DataFrame(columns=['word1', 'word2', 'cosine distance'])\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if cos_dis_arr_rounded_no_repeats[i,j] != 0:\n",
    "            cos_dis_df.loc[len(cos_dis_df)] = {'word1': first_ten_words.iloc[i,0], 'word2': first_ten_words.iloc[j,0], 'cosine distance': cos_dis_arr_rounded_no_repeats[i,j]}\n",
    "\n",
    "cos_dis_dif = cos_dis_df.sort_values('cosine distance')\n",
    "print(cos_dis_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c37b3-a4a1-400b-9c84-f30bbc44faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9acc6b69-2c27-48bc-a608-1924bed33cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for operation:  0.8017599582672119\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "embeddings = d.iloc[:100000, 1:].to_numpy().astype('float32')\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time for operation: ', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "92f0ca16-2950-472c-99c2-47de47e92e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in index: 100000\n"
     ]
    }
   ],
   "source": [
    "print('Number of vectors in index:', index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dedb55d2-f18b-44d3-a359-a0da252e8733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding array size (MB): 38.14697265625\n"
     ]
    }
   ],
   "source": [
    "print('Embedding array size (MB):', embeddings.nbytes / (1024*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e5e47ce4-277c-4c5c-aa82-de6db8b78378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for operation:  0.16666269302368164\n"
     ]
    }
   ],
   "source": [
    "#refers to the row index from the previous cell as the query for index.search()\n",
    "#the is the number of neighbors to return\n",
    "query_word = 'data'\n",
    "n_neighbors_to_fetch = 31\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "query_word_token = embeddings[d[d[0]==query_word].index[0] : d[d[0]==query_word].index[0]+1]\n",
    "distances_to_knn, indices_of_knn = index.search(query_word_token, n_neighbors_to_fetch)\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time for operation: ', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bd9c9bed-9385-4b2e-92dc-a8ecbb64e3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.84648 , -0.082548, -1.301806, -0.735832,  0.674053, -0.196307,\n",
       "        -1.096278, -0.580526, -0.385972, -0.283625,  0.120287, -0.952777,\n",
       "         1.016617, -0.34848 , -0.342494,  0.459328,  0.695805, -0.33583 ,\n",
       "         0.6236  , -0.207273,  0.335618,  1.056428,  0.557629, -0.070907,\n",
       "        -0.928007, -0.65674 ,  0.343962, -0.501568, -0.754843,  0.063396,\n",
       "         0.569669,  0.214937, -0.640749, -0.431692, -4.343161,  0.339861,\n",
       "        -0.179838, -0.272953,  0.278215,  0.316486,  0.153532,  0.213689,\n",
       "         0.29925 , -0.724164,  0.035117,  0.187556, -0.343278,  0.197821,\n",
       "         0.379513,  0.502576,  0.766893,  0.476763, -0.228328,  0.294447,\n",
       "        -0.714183,  0.493492,  0.930728, -0.21876 ,  0.623998, -0.252814,\n",
       "        -0.233913,  0.116794, -0.119629,  0.60437 , -0.737304,  0.483543,\n",
       "        -0.488996, -0.38302 , -0.735055, -0.470569, -0.019399,  0.970328,\n",
       "         0.087283,  1.061838, -0.946366,  0.729165,  0.334329,  0.116828,\n",
       "        -0.365285,  0.300026,  0.521133, -0.005573,  0.147514, -0.274999,\n",
       "        -0.091457,  0.188029,  0.008066,  0.769442,  1.161058, -0.581499,\n",
       "         0.004657,  0.015505, -0.424648,  0.198222,  0.627702,  0.677911,\n",
       "        -0.263496, -0.26085 , -0.518376, -0.15061 ]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_word_token"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining_assignment_2_similarity_venv",
   "language": "python",
   "name": "data_mining_assignment_2_similarity_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
