{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30a67f30-0009-4f07-8bf2-f7eaf6c03fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3c624ff-e9b1-4531-983f-aaaf50dd2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9506825-26e0-4846-bd9e-eda6aa13fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('data/tokens.txt', header=None, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "569f933d-f31d-42dc-a3f7-bac1dc82d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.to_pickle('data/tokens.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e38a70-658d-42e0-9542-b9068d66e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = pd.read_pickle('data/tokens.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f077833-2dda-4f1e-9084-be6bc12440b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0         1         2\n",
      "0                                                 the  0.306717 -0.320530\n",
      "1                                                   ,  0.022532  0.320788\n",
      "2                                                   . -0.075626  0.369955\n",
      "3                                                  of  0.487177 -0.193218\n",
      "4                                                  to  0.173940 -0.104660\n",
      "5                                                 and  0.222883 -0.001161\n",
      "6                                                  in  0.712315  0.451855\n",
      "7                                                   a  0.048874  0.379618\n",
      "8    0.019833000000000017 0.13675199999999998 -0.4... -0.246612  0.579491\n",
      "9                                               1,028  0.173451  0.174839\n",
      "10                                                12m  0.296672 -0.595140\n",
      "11                                               2037 -0.612709 -0.547751\n",
      "12                                              3,197 -1.888887  0.445365\n",
      "13                                               9.43  0.080744  0.289626\n",
      "14                                             aagpbl  0.904035  0.109863\n",
      "15                                       acetaldehyde -0.660866  0.676913\n",
      "16                                         bafflement  0.811863 -0.274113\n",
      "17                                            berhanu  1.246377  0.203939\n",
      "18                                          bookended  0.344131 -0.153467\n",
      "19                                          cassibile  0.418444  1.962077\n",
      "20                                         courtaulds  0.060361  0.103459\n",
      "21                                                d12 -0.283005 -0.834415\n",
      "22                                            dillane  0.104478 -0.518709\n",
      "23                                             droids  0.199113 -0.865547\n",
      "24                                                eam -0.749088  0.017199\n",
      "25                                             encase -0.061719 -0.571921\n",
      "26                                              giani -0.290570  1.290203\n",
      "27                                         grumblings  0.928575 -0.848395\n",
      "28                                             gulick -0.083290  0.530718\n",
      "29                                               haat -0.395927 -1.105183\n"
     ]
    }
   ],
   "source": [
    "# print(d.iloc[:30, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c56b5103-2cdf-4f45-b50f-fef8da6e3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ten_words = d.iloc[[0,3,4,5,6,7,15,16,17,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "73f54333-153d-4a4f-9ef4-793a83bd695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.145 0.199 0.205 0.153 0.18  1.118 1.077 1.13  1.088]\n",
      " [0.145 0.    0.271 0.191 0.173 0.209 1.068 1.052 1.083 1.154]\n",
      " [0.199 0.271 0.    0.194 0.218 0.25  1.069 1.059 1.134 1.255]\n",
      " [0.205 0.191 0.194 0.    0.172 0.262 1.109 1.063 1.084 1.143]\n",
      " [0.153 0.173 0.218 0.172 0.    0.189 1.097 1.113 1.143 1.106]\n",
      " [0.18  0.209 0.25  0.262 0.189 0.    1.095 1.079 1.156 1.102]\n",
      " [1.118 1.068 1.069 1.109 1.097 1.095 0.    0.796 1.026 0.884]\n",
      " [1.077 1.052 1.059 1.063 1.113 1.079 0.796 0.    0.861 0.841]\n",
      " [1.13  1.083 1.134 1.084 1.143 1.156 1.026 0.861 0.    0.905]\n",
      " [1.088 1.154 1.255 1.143 1.106 1.102 0.884 0.841 0.905 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "#cosine similarity = v1 dot v2 / (norm(v1) * norm(v2))\n",
    "#cosine distance = 1 - cosine similarity\n",
    "\n",
    "cos_similarities = np.empty((10,10))\n",
    "for i in range(10):\n",
    "    for j in range (10):\n",
    "        cos_similarities[i, j] = np.dot(first_ten_words.iloc[i, 1:], first_ten_words.iloc[j, 1:]) / (np.linalg.norm(first_ten_words.iloc[i, 1:]) * np.linalg.norm(first_ten_words.iloc[j, 1:]))\n",
    "cos_similarities = np.clip(cos_similarities, -1, 1) #clipped to fix a rounding error\n",
    "cos_distances = 1 - cos_similarities\n",
    "\n",
    "print(np.round(cos_distances, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e55a6423-0fe2-4ded-a648-0f3d96841e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.545 0.642 0.652 0.56  0.61  1.689 1.648 1.701 1.659]\n",
      " [0.545 0.    0.753 0.628 0.598 0.658 1.639 1.622 1.654 1.726]\n",
      " [0.642 0.753 0.    0.633 0.673 0.723 1.64  1.63  1.705 1.828]\n",
      " [0.652 0.628 0.633 0.    0.595 0.741 1.68  1.634 1.655 1.714]\n",
      " [0.56  0.598 0.673 0.595 0.    0.626 1.668 1.684 1.714 1.677]\n",
      " [0.61  0.658 0.723 0.741 0.626 0.    1.666 1.65  1.727 1.673]\n",
      " [1.689 1.639 1.64  1.68  1.668 1.666 0.    1.366 1.597 1.455]\n",
      " [1.648 1.622 1.63  1.634 1.684 1.65  1.366 0.    1.431 1.411]\n",
      " [1.701 1.654 1.705 1.655 1.714 1.727 1.597 1.431 0.    1.476]\n",
      " [1.659 1.726 1.828 1.714 1.677 1.673 1.455 1.411 1.476 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "#angular distance = arccos(v1 dot v2 / (norm(v1) * norm(v2)))\n",
    "\n",
    "angular_distances = np.arccos(cos_similarities)\n",
    "\n",
    "print(np.round(angular_distances, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "707e3a6b-0649-4e2c-8658-6d1467e1609f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word1         word2  angular distance\n",
      "0             of           the            0.5455\n",
      "6             in           the            0.5601\n",
      "9             in           and            0.5945\n",
      "7             in            of            0.5979\n",
      "10             a           the            0.6097\n",
      "14             a            in            0.6257\n",
      "4            and            of            0.6276\n",
      "5            and            to            0.6329\n",
      "1             to           the            0.6416\n",
      "3            and           the            0.6518\n",
      "11             a            of            0.6582\n",
      "8             in            to            0.6727\n",
      "12             a            to            0.7225\n",
      "13             a           and            0.7407\n",
      "2             to            of            0.7534\n",
      "27    bafflement  acetaldehyde            1.3659\n",
      "43     bookended    bafflement            1.4108\n",
      "35       berhanu    bafflement            1.4315\n",
      "42     bookended  acetaldehyde            1.4547\n",
      "44     bookended       berhanu            1.4758\n",
      "34       berhanu  acetaldehyde            1.5967\n",
      "22    bafflement            of            1.6225\n",
      "23    bafflement            to            1.6298\n",
      "24    bafflement           and            1.6342\n",
      "16  acetaldehyde            of            1.6392\n",
      "17  acetaldehyde            to            1.6396\n",
      "21    bafflement           the            1.6476\n",
      "26    bafflement             a            1.6504\n",
      "29       berhanu            of            1.6543\n",
      "31       berhanu           and            1.6552\n",
      "36     bookended           the            1.6586\n",
      "20  acetaldehyde             a            1.6659\n",
      "19  acetaldehyde            in            1.6679\n",
      "41     bookended             a            1.6731\n",
      "40     bookended            in            1.6771\n",
      "18  acetaldehyde           and            1.6795\n",
      "25    bafflement            in            1.6839\n",
      "15  acetaldehyde           the            1.6892\n",
      "28       berhanu           the            1.7009\n",
      "30       berhanu            to            1.7054\n",
      "32       berhanu            in            1.7138\n",
      "39     bookended           and            1.7140\n",
      "37     bookended            of            1.7259\n",
      "33       berhanu             a            1.7272\n",
      "38     bookended            to            1.8284\n"
     ]
    }
   ],
   "source": [
    "ang_dis_arr_rounded_no_repeats = np.tril(np.round(angular_distances, decimals=4))\n",
    "ang_dis_df = pd.DataFrame(columns=['word1', 'word2', 'angular distance'])\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if ang_dis_arr_rounded_no_repeats[i,j] != 0:\n",
    "            ang_dis_df.loc[len(ang_dis_df)] = {'word1': first_ten_words.iloc[i,0], 'word2': first_ten_words.iloc[j,0], 'angular distance': ang_dis_arr_rounded_no_repeats[i,j]}\n",
    "\n",
    "ang_dis_dif = ang_dis_df.sort_values('angular distance')\n",
    "print(ang_dis_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "722227e5-d512-4723-af17-5208e1306980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for comparison - the list is the same with both distances measures\n",
    "\n",
    "cos_dis_arr_rounded_no_repeats = np.tril(np.round(cos_distances, decimals=4))\n",
    "cos_dis_df = pd.DataFrame(columns=['word1', 'word2', 'cosine distance'])\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if cos_dis_arr_rounded_no_repeats[i,j] != 0:\n",
    "            cos_dis_df.loc[len(cos_dis_df)] = {'word1': first_ten_words.iloc[i,0], 'word2': first_ten_words.iloc[j,0], 'cosine distance': cos_dis_arr_rounded_no_repeats[i,j]}\n",
    "\n",
    "cos_dis_dif = cos_dis_df.sort_values('cosine distance')\n",
    "#print(cos_dis_dif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining_assignment_2_similarity_venv",
   "language": "python",
   "name": "data_mining_assignment_2_similarity_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
